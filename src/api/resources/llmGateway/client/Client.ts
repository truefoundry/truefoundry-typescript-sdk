/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as core from "../../../../core/index.js";
import * as TrueFoundry from "../../../index.js";
import { mergeHeaders, mergeOnlyDefinedHeaders } from "../../../../core/headers.js";
import * as errors from "../../../../errors/index.js";

export declare namespace LlmGateway {
    export interface Options {
        environment: core.Supplier<string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<core.BearerToken | undefined>;
        /** Additional headers to include in requests. */
        headers?: Record<string, string | core.Supplier<string | undefined> | undefined>;
        fetcher?: core.FetchFunction;
    }

    export interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Additional headers to include in the request. */
        headers?: Record<string, string | core.Supplier<string | undefined> | undefined>;
    }
}

export class LlmGateway {
    protected readonly _options: LlmGateway.Options;

    constructor(_options: LlmGateway.Options) {
        this._options = _options;
    }

    /**
     * @param {TrueFoundry.GetLlmGatewayMetricsRequestDto} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcMetricsGetLlmPlaygroundTables()
     */
    public svcMetricsGetLlmPlaygroundTables(
        request: TrueFoundry.GetLlmGatewayMetricsRequestDto = {},
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(this.__svcMetricsGetLlmPlaygroundTables(request, requestOptions));
    }

    private async __svcMetricsGetLlmPlaygroundTables(
        request: TrueFoundry.GetLlmGatewayMetricsRequestDto = {},
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/metrics/tables",
            ),
            method: "POST",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            contentType: "application/json",
            requestType: "json",
            body: request,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling POST /api/svc/v1/llm-gateway/metrics/tables.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcInferenceRequestGetFilterTypeAndLabelValues()
     */
    public svcInferenceRequestGetFilterTypeAndLabelValues(
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(
            this.__svcInferenceRequestGetFilterTypeAndLabelValues(requestOptions),
        );
    }

    private async __svcInferenceRequestGetFilterTypeAndLabelValues(
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/requests/column-details",
            ),
            method: "GET",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling GET /api/svc/v1/llm-gateway/requests/column-details.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves available MCP metrics charts.
     *
     * @param {TrueFoundry.SvcMcpMetricsGetMcpMetricsChartsRequest} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcMcpMetricsGetMcpMetricsCharts({
     *         page: "mcpserver"
     *     })
     */
    public svcMcpMetricsGetMcpMetricsCharts(
        request: TrueFoundry.SvcMcpMetricsGetMcpMetricsChartsRequest,
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<TrueFoundry.McpMetricsChartsResponseDto> {
        return core.HttpResponsePromise.fromPromise(this.__svcMcpMetricsGetMcpMetricsCharts(request, requestOptions));
    }

    private async __svcMcpMetricsGetMcpMetricsCharts(
        request: TrueFoundry.SvcMcpMetricsGetMcpMetricsChartsRequest,
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<TrueFoundry.McpMetricsChartsResponseDto>> {
        const { page } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        _queryParams["page"] = page;
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/mcp-metrics/charts",
            ),
            method: "GET",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            queryParameters: _queryParams,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: _response.body as TrueFoundry.McpMetricsChartsResponseDto,
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling GET /api/svc/v1/llm-gateway/mcp-metrics/charts.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves available MCP metrics filters.
     *
     * @param {TrueFoundry.SvcMcpMetricsGetMcpMetricsFiltersRequest} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcMcpMetricsGetMcpMetricsFilters({
     *         startTime: 1710201609,
     *         endTime: 1710202200,
     *         page: "mcpserver"
     *     })
     */
    public svcMcpMetricsGetMcpMetricsFilters(
        request: TrueFoundry.SvcMcpMetricsGetMcpMetricsFiltersRequest,
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<TrueFoundry.McpMetricsFiltersResponseDto> {
        return core.HttpResponsePromise.fromPromise(this.__svcMcpMetricsGetMcpMetricsFilters(request, requestOptions));
    }

    private async __svcMcpMetricsGetMcpMetricsFilters(
        request: TrueFoundry.SvcMcpMetricsGetMcpMetricsFiltersRequest,
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<TrueFoundry.McpMetricsFiltersResponseDto>> {
        const { startTime, endTime, page } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        _queryParams["startTime"] = startTime.toString();
        _queryParams["endTime"] = endTime.toString();
        _queryParams["page"] = page;
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/mcp-metrics/filters",
            ),
            method: "GET",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            queryParameters: _queryParams,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: _response.body as TrueFoundry.McpMetricsFiltersResponseDto,
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling GET /api/svc/v1/llm-gateway/mcp-metrics/filters.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves aggregated MCP metrics data.
     *
     * @param {TrueFoundry.McpMetersRequestDto} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcMcpMetricsGetMcpMeters({
     *         page: "mcpserver"
     *     })
     */
    public svcMcpMetricsGetMcpMeters(
        request: TrueFoundry.McpMetersRequestDto,
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<TrueFoundry.McpMetersResponseDto> {
        return core.HttpResponsePromise.fromPromise(this.__svcMcpMetricsGetMcpMeters(request, requestOptions));
    }

    private async __svcMcpMetricsGetMcpMeters(
        request: TrueFoundry.McpMetersRequestDto,
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<TrueFoundry.McpMetersResponseDto>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/mcp-metrics/meters",
            ),
            method: "POST",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            contentType: "application/json",
            requestType: "json",
            body: request,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: _response.body as TrueFoundry.McpMetersResponseDto, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling POST /api/svc/v1/llm-gateway/mcp-metrics/meters.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves available MCP metrics charts.
     *
     * @param {TrueFoundry.McpMetricsChartsDataRequestDto} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcMcpMetricsGetMcpMetricsChartsData({
     *         startTime: 1710201609,
     *         endTime: 1710202200,
     *         chartName: "rateOfRequestsPerMcpServer"
     *     })
     */
    public svcMcpMetricsGetMcpMetricsChartsData(
        request: TrueFoundry.McpMetricsChartsDataRequestDto,
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(
            this.__svcMcpMetricsGetMcpMetricsChartsData(request, requestOptions),
        );
    }

    private async __svcMcpMetricsGetMcpMetricsChartsData(
        request: TrueFoundry.McpMetricsChartsDataRequestDto,
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/mcp-metrics/chartsData",
            ),
            method: "POST",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            contentType: "application/json",
            requestType: "json",
            body: request,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling POST /api/svc/v1/llm-gateway/mcp-metrics/chartsData.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves available Guardrail metrics charts.
     *
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcGuardrailMetricsGetGuardrailMetricsCharts()
     */
    public svcGuardrailMetricsGetGuardrailMetricsCharts(
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<TrueFoundry.GuardrailMetricsChartsResponseDto> {
        return core.HttpResponsePromise.fromPromise(
            this.__svcGuardrailMetricsGetGuardrailMetricsCharts(requestOptions),
        );
    }

    private async __svcGuardrailMetricsGetGuardrailMetricsCharts(
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<TrueFoundry.GuardrailMetricsChartsResponseDto>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/guardrail-metrics/charts",
            ),
            method: "GET",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: _response.body as TrueFoundry.GuardrailMetricsChartsResponseDto,
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling GET /api/svc/v1/llm-gateway/guardrail-metrics/charts.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves available Guardrail metrics filters.
     *
     * @param {TrueFoundry.SvcGuardrailMetricsGetGuardrailMetricsFiltersRequest} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcGuardrailMetricsGetGuardrailMetricsFilters({
     *         startTime: 1710201609,
     *         endTime: 1710202200
     *     })
     */
    public svcGuardrailMetricsGetGuardrailMetricsFilters(
        request: TrueFoundry.SvcGuardrailMetricsGetGuardrailMetricsFiltersRequest,
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<TrueFoundry.GuardrailMetricsFiltersResponseDto> {
        return core.HttpResponsePromise.fromPromise(
            this.__svcGuardrailMetricsGetGuardrailMetricsFilters(request, requestOptions),
        );
    }

    private async __svcGuardrailMetricsGetGuardrailMetricsFilters(
        request: TrueFoundry.SvcGuardrailMetricsGetGuardrailMetricsFiltersRequest,
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<TrueFoundry.GuardrailMetricsFiltersResponseDto>> {
        const { startTime, endTime } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        _queryParams["startTime"] = startTime.toString();
        _queryParams["endTime"] = endTime.toString();
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/guardrail-metrics/filters",
            ),
            method: "GET",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            queryParameters: _queryParams,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: _response.body as TrueFoundry.GuardrailMetricsFiltersResponseDto,
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling GET /api/svc/v1/llm-gateway/guardrail-metrics/filters.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves aggregated Guardrail metrics data.
     *
     * @param {TrueFoundry.GuardrailMetersRequestDto} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcGuardrailMetricsGetGuardrailMeters()
     */
    public svcGuardrailMetricsGetGuardrailMeters(
        request: TrueFoundry.GuardrailMetersRequestDto = {},
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<TrueFoundry.GuardrailMetersResponseDto> {
        return core.HttpResponsePromise.fromPromise(
            this.__svcGuardrailMetricsGetGuardrailMeters(request, requestOptions),
        );
    }

    private async __svcGuardrailMetricsGetGuardrailMeters(
        request: TrueFoundry.GuardrailMetersRequestDto = {},
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<TrueFoundry.GuardrailMetersResponseDto>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/guardrail-metrics/meters",
            ),
            method: "POST",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            contentType: "application/json",
            requestType: "json",
            body: request,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: _response.body as TrueFoundry.GuardrailMetersResponseDto,
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling POST /api/svc/v1/llm-gateway/guardrail-metrics/meters.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Retrieves Guardrail metrics charts data.
     *
     * @param {TrueFoundry.GuardrailMetricsChartsDataRequestDto} request
     * @param {LlmGateway.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmGateway.svcGuardrailMetricsGetGuardrailMetricsChartsData({
     *         startTime: 1710201609,
     *         endTime: 1710202200,
     *         chartName: "rateOfRequestsPerGuardrail"
     *     })
     */
    public svcGuardrailMetricsGetGuardrailMetricsChartsData(
        request: TrueFoundry.GuardrailMetricsChartsDataRequestDto,
        requestOptions?: LlmGateway.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(
            this.__svcGuardrailMetricsGetGuardrailMetricsChartsData(request, requestOptions),
        );
    }

    private async __svcGuardrailMetricsGetGuardrailMetricsChartsData(
        request: TrueFoundry.GuardrailMetricsChartsDataRequestDto,
        requestOptions?: LlmGateway.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)),
                "api/svc/v1/llm-gateway/guardrail-metrics/chartsData",
            ),
            method: "POST",
            headers: mergeHeaders(
                this._options?.headers,
                mergeOnlyDefinedHeaders({ Authorization: await this._getAuthorizationHeader() }),
                requestOptions?.headers,
            ),
            contentType: "application/json",
            requestType: "json",
            body: request,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.TrueFoundryError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TrueFoundryError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TrueFoundryTimeoutError(
                    "Timeout exceeded when calling POST /api/svc/v1/llm-gateway/guardrail-metrics/chartsData.",
                );
            case "unknown":
                throw new errors.TrueFoundryError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    protected async _getAuthorizationHeader(): Promise<string> {
        const bearer = (await core.Supplier.get(this._options.apiKey)) ?? process?.env["TFY_API_KEY"];
        if (bearer == null) {
            throw new errors.TrueFoundryError({
                message:
                    "Please specify a bearer by either passing it in to the constructor or initializing a TFY_API_KEY environment variable",
            });
        }

        return `Bearer ${bearer}`;
    }
}
