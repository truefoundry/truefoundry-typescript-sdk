// This file was auto-generated by Fern from our API Definition.

import type * as TrueFoundry from "../index.js";

/**
 * Configure resource allocations, specify node constraints and capacity types to improve performance and reduce expenses. [Docs](https://docs.truefoundry.com/docs/resources)
 */
export interface Resources {
    /**
     * Requested CPU which determines the minimum cost incurred. The CPU usage can exceed the requested
     * amount, but not the value specified in the limit. 1 CPU means 1 CPU core. Fractional CPU can be requested
     * like `0.5` or `0.05`
     */
    cpu_request: number;
    /**
     * CPU limit beyond which the usage cannot be exceeded. 1 CPU means 1 CPU core. Fractional CPU can be requested
     * like `0.5`. CPU limit should be >= cpu request.
     */
    cpu_limit: number;
    /**
     * Requested memory which determines the minimum cost incurred. The unit of memory is in megabytes(MB).
     * So 1 means 1 MB and 2000 means 2GB.
     */
    memory_request: number;
    /**
     * Memory limit after which the application will be killed with an OOM error. The unit of memory is
     * in megabytes(MB). So 1 means 1 MB and 2000 means 2GB. MemoryLimit should be greater than memory request.
     */
    memory_limit: number;
    /**
     * Requested disk storage. The unit of memory is in megabytes(MB).
     * This is ephemeral storage and will be wiped out on pod restarts or eviction
     */
    ephemeral_storage_request: number;
    /**
     * Disk storage limit. The unit of memory is in megabytes(MB). Exceeding this limit will result in eviction.
     * It should be greater than the request. This is ephemeral storage and will be wiped out on pod restarts or eviction
     */
    ephemeral_storage_limit: number;
    /**
     * Define the shared memory requirements for your workload. Machine learning libraries like Pytorch can use Shared Memory
     * for inter-process communication. If you use this, we will mount a `tmpfs` backed volume at the `/dev/shm` directory.
     * Any usage will also count against the workload's memory limit (`resources.memory_limit`) along with your workload's memory usage.
     * If the overall usage goes above `resources.memory_limit` the user process may get killed.
     * Shared Memory Size cannot be more than the defined Memory Limit for the workload.
     */
    shared_memory_size?: number;
    /** This field determines how the underlying node resource is to be utilized */
    node?: TrueFoundry.ResourcesNode;
    /** Define custom device or accelerator requirements for your workload. We currently support NVIDIA GPUs, AWS Inferentia Accelerators, Single Host TPU Slices. */
    devices?: TrueFoundry.ResourcesDevicesItem[];
}
