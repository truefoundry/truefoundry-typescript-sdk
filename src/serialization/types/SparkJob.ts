/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index.js";
import * as TrueFoundry from "../../api/index.js";
import * as core from "../../core/index.js";
import { SparkJobImage } from "./SparkJobImage";
import { SparkJobEntrypoint } from "./SparkJobEntrypoint";
import { SparkDriverConfig } from "./SparkDriverConfig.js";
import { SparkExecutorConfig } from "./SparkExecutorConfig.js";
import { VolumeMount } from "./VolumeMount.js";

export const SparkJob: core.serialization.ObjectSchema<serializers.SparkJob.Raw, TrueFoundry.SparkJob> =
    core.serialization.object({
        type: core.serialization.stringLiteral("spark-job"),
        name: core.serialization.string(),
        image: SparkJobImage,
        entrypoint: SparkJobEntrypoint,
        driver_config: SparkDriverConfig,
        executor_config: SparkExecutorConfig,
        env: core.serialization.record(core.serialization.string(), core.serialization.unknown()).optional(),
        spark_conf: core.serialization.record(core.serialization.string(), core.serialization.unknown()).optional(),
        mounts: core.serialization.list(VolumeMount).optional(),
        retries: core.serialization.number().optional(),
        service_account: core.serialization.string().optional(),
        workspace_fqn: core.serialization.string().optional(),
    });

export declare namespace SparkJob {
    export interface Raw {
        type: "spark-job";
        name: string;
        image: SparkJobImage.Raw;
        entrypoint: SparkJobEntrypoint.Raw;
        driver_config: SparkDriverConfig.Raw;
        executor_config: SparkExecutorConfig.Raw;
        env?: Record<string, unknown> | null;
        spark_conf?: Record<string, unknown> | null;
        mounts?: VolumeMount.Raw[] | null;
        retries?: number | null;
        service_account?: string | null;
        workspace_fqn?: string | null;
    }
}
